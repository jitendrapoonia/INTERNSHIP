{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812d090f",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display IMDB’s Top rated 100 Indian movies’ data\n",
    "https://www.imdb.com/list/ls056092300/ (i.e. name, rating, year ofrelease) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcbb5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Name Rating    Year\n",
      "0                     Ship of Theseus      8  (2012)\n",
      "1                              Iruvar    8.4  (1997)\n",
      "2                     Kaagaz Ke Phool    7.8  (1959)\n",
      "3   Lagaan: Once Upon a Time in India    8.1  (2001)\n",
      "4                     Pather Panchali    8.2  (1955)\n",
      "..                                ...    ...     ...\n",
      "95                        Apur Sansar    8.4  (1959)\n",
      "96                        Kanchivaram    8.2  (2008)\n",
      "97                    Monsoon Wedding    7.3  (2001)\n",
      "98                              Black    8.1  (2005)\n",
      "99                            Deewaar      8  (1975)\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls056092300/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movie_items = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "\n",
    "names = []\n",
    "ratings = []\n",
    "years = []\n",
    "\n",
    "for item in movie_items:\n",
    "    name = item.find(\"h3\").find(\"a\").text.strip()\n",
    "    names.append(name)\n",
    "\n",
    "    rating = item.find(\"span\", class_=\"ipl-rating-star__rating\").text.strip()\n",
    "    ratings.append(rating)\n",
    "\n",
    "    year = item.find(\"span\", class_=\"lister-item-year\").text.strip()\n",
    "    years.append(year)\n",
    "\n",
    "movie_data = pd.DataFrame({\n",
    "    \"Name\": names,\n",
    "    \"Rating\": ratings,\n",
    "    \"Year\": years\n",
    "})\n",
    "\n",
    "print(movie_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd8720",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape details of all the posts from https://www.patreon.com/coreyms .Scrape the\n",
    "heading, date, content and the likes for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cb9235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_patreon_posts(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    posts = []\n",
    "\n",
    "    for post in soup.find_all('div', class_='post-card'):\n",
    "        heading = post.find('h3', class_='post-card__title').text.strip()\n",
    "\n",
    "        date = post.find('time', class_='post-card__published-at')['datetime']\n",
    "\n",
    "        content = post.find('div', class_='post-card__excerpt').text.strip()\n",
    "\n",
    "        youtube_link = post.find('a', href=lambda href: href and 'youtube.com' in href)\n",
    "        likes = None\n",
    "        if youtube_link:\n",
    "            youtube_url = youtube_link['href']\n",
    "            likes = get_youtube_likes(youtube_url)\n",
    "\n",
    "        posts.append({\n",
    "            'heading': heading,\n",
    "            'date': date,\n",
    "            'content': content,\n",
    "            'likes': likes\n",
    "        })\n",
    "\n",
    "    return posts\n",
    "\n",
    "def get_youtube_likes(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    likes_text = soup.find('button', attrs={'aria-label': 'like this video'})\n",
    "    if likes_text:\n",
    "        likes = likes_text.find_next('div').text.strip()\n",
    "        return likes\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.patreon.com/coreyms\"\n",
    "    posts = scrape_patreon_posts(url)\n",
    "\n",
    "    for post in posts:\n",
    "        print(\"Heading:\", post['heading'])\n",
    "        print(\"Date:\", post['date'])\n",
    "        print(\"Content:\", post['content'])\n",
    "        print(\"Likes:\", post['likes'])\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba613ef",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar,\n",
    "Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ccd4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houses in Indira Nagar:\n",
      "\n",
      "Houses in Jayanagar:\n",
      "\n",
      "Houses in Rajaji Nagar:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_house_details(locality):\n",
    "    url = f\"https://www.nobroker.in/property/sale/{locality}/bangalore?searchParam=W3sibGF0IjoxOC4wMDg3Mjg0LCJsb24iOjc3LjY4Mjg5MjQsInBsYWNlSWQiOiJDaElKbFpYM1hvY3pYM29zaVhzbVVaazZYT2wiLCJwbGFjZU5hbWUiOiJJbmRpcmEgTmFnYXIsIFJlYWQgQW5nZWwifV0=&radius=2.0\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    houses = []\n",
    "\n",
    "    house_cards = soup.find_all('div', class_='card')\n",
    "    for card in house_cards:\n",
    "        title = card.find('h2', class_='heading-6').text.strip()\n",
    "        location = card.find('div', class_='nb__2CMjv').text.strip()\n",
    "        area = card.find('div', class_='nb__3oNyC').text.strip()\n",
    "        emi = card.find('div', class_='font-semi-bold heading-6').text.strip()\n",
    "        price = card.find('div', class_='heading-7').text.strip()\n",
    "\n",
    "        houses.append({\n",
    "            'title': title,\n",
    "            'location': location,\n",
    "            'area': area,\n",
    "            'emi': emi,\n",
    "            'price': price\n",
    "        })\n",
    "\n",
    "    return houses\n",
    "\n",
    "def main():\n",
    "    localities = [\"Indira%20Nagar\", \"Jayanagar\", \"Rajaji%20Nagar\"]\n",
    "    \n",
    "    for locality in localities:\n",
    "        print(f\"Houses in {locality.replace('%20', ' ')}:\")\n",
    "        houses = scrape_house_details(locality)\n",
    "        for house in houses:\n",
    "            print(house)\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e3a32",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/bestseller?sort=popular . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49cd8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_products(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    products = []\n",
    "\n",
    "    product_cards = soup.find_all('div', class_='product-card')\n",
    "    for card in product_cards[:10]:\n",
    "        product_name_element = card.find('h4', class_='product-card__title')\n",
    "        price_element = card.find('span', class_='product-card__price')\n",
    "        image_element = card.find('img', class_='product-card__img')\n",
    "\n",
    "        if product_name_element and price_element and image_element:\n",
    "            product_name = product_name_element.text.strip()\n",
    "            price = price_element.text.strip()\n",
    "            image_url = image_element['src']\n",
    "\n",
    "            products.append({\n",
    "                'product_name': product_name,\n",
    "                'price': price,\n",
    "                'image_url': image_url\n",
    "            })\n",
    "\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.bewakoof.com/bestseller?sort=popular\"\n",
    "    products = scrape_products(url)\n",
    "\n",
    "    for index, product in enumerate(products, start=1):\n",
    "        print(f\"Product {index}:\")\n",
    "        print(\"Name:\", product['product_name'])\n",
    "        print(\"Price:\", product['price'])\n",
    "        print(\"Image URL:\", product['image_url'])\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f07c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
